{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4def829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import k3d\n",
    "from matplotlib import cm, colors\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d1f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pointcloud(point_cloud, point_size=0.05, colors=None, flip_axes=False, name='point_cloud'):\n",
    "    plot = k3d.plot(name=name, grid_visible=False)\n",
    "    if flip_axes:\n",
    "        point_cloud[:, 2] = point_cloud[:, 2] * -1\n",
    "        point_cloud[:, [0, 1, 2]] = point_cloud[:, [0, 2, 1]]\n",
    "    plt_points = k3d.points(positions=point_cloud.astype(np.float32), point_size=point_size, colors=colors if colors is not None else [], color=0xd0d0d0)\n",
    "    plot += plt_points\n",
    "    plt_points.shader = '3d'\n",
    "    return plot.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba2ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(coord, prediction):\n",
    "    point_labels = (prediction - min(prediction)) / (max(prediction) - min(prediction))\n",
    "    point_colors = cm.get_cmap('hsv')(point_labels)[:, :3]\n",
    "    point_colors = np.sum((point_colors * 255).astype(int) * [255*255, 255, 1], axis=1)\n",
    "    visualize_pointcloud(coord, colors=point_colors, point_size=0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a76abf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
    "    if (y.is_cuda):\n",
    "        return new_y.cuda()\n",
    "    return new_y\n",
    "\n",
    "def infer(model, item):\n",
    "    seg_classes = {'Earphone': [16, 17, 18], 'Motorbike': [30, 31, 32, 33, 34, 35], 'Rocket': [41, 42, 43],\n",
    "               'Car': [8, 9, 10, 11], 'Laptop': [28, 29], 'Cap': [6, 7], 'Skateboard': [44, 45, 46], 'Mug': [36, 37],\n",
    "               'Guitar': [19, 20, 21], 'Bag': [4, 5], 'Lamp': [24, 25, 26, 27], 'Table': [47, 48, 49],\n",
    "               'Airplane': [0, 1, 2, 3], 'Pistol': [38, 39, 40], 'Chair': [12, 13, 14, 15], 'Knife': [22, 23]}\n",
    "    seg_label_to_cat = {}  # {0:Airplane, 1:Airplane, ...49:Table}\n",
    "    for cat in seg_classes.keys():\n",
    "        for label in seg_classes[cat]:\n",
    "            seg_label_to_cat[label] = cat\n",
    "\n",
    "    with torch.no_grad():\n",
    "        seg_label_to_cat = {}  # {0:Airplane, 1:Airplane, ...49:Table}\n",
    "\n",
    "        for cat in seg_classes.keys():\n",
    "            for label in seg_classes[cat]:\n",
    "                seg_label_to_cat[label] = cat\n",
    "\n",
    "        model = model.eval()\n",
    "        (points, label, target) = item\n",
    "        points = torch.from_numpy(points).unsqueeze(0)\n",
    "        label = torch.from_numpy(label).unsqueeze(0)\n",
    "        target = torch.from_numpy(target).unsqueeze(0)\n",
    "        \n",
    "        cur_batch_size, NUM_POINT, _ = points.size()\n",
    "        points, label, target = points.float().cuda(), label.long().cuda(), target.long().cuda()\n",
    "        seg_pred = model(torch.cat([points, to_categorical(label, num_category).repeat(1, points.shape[1], 1)], -1))\n",
    "        cur_pred_val = seg_pred.cpu().data.numpy()\n",
    "        cur_pred_val_logits = cur_pred_val\n",
    "        cur_pred_val = np.zeros((cur_batch_size, NUM_POINT)).astype(np.int32)\n",
    "        target = target.cpu().data.numpy()\n",
    "\n",
    "        for i in range(cur_batch_size):\n",
    "            cat = seg_label_to_cat[target[i, 0]]\n",
    "            logits = cur_pred_val_logits[i, :, :]\n",
    "            cur_pred_val[i, :] = np.argmax(logits[:, seg_classes[cat]], 1) + seg_classes[cat][0]\n",
    "\n",
    "        return points, cur_pred_val, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49ba2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import PartNormalDataset\n",
    "from models.Hengshuang.model import PointTransformerSeg\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "model_path = \"/home/nazmicancalik/workspace/pc-transformers-with-convolution/Point-Transformers/log/partseg/Hengshuang/best_model.pth\"\n",
    "root = \"/home/nazmicancalik/workspace/pc-transformers-with-convolution/Point-Transformers/data/shapenetcore_partanno_segmentation_benchmark_v0_normal/\"\n",
    "\n",
    "num_point = 1024\n",
    "normal = True\n",
    "batch_size = 16\n",
    "num_category = 16\n",
    "\n",
    "TEST_DATASET = PartNormalDataset(root=root, npoints=num_point, split='test', normal_channel=normal)\n",
    "testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "\n",
    "num_class = 50\n",
    "num_part = num_class\n",
    "\n",
    "# Set config\n",
    "cfg = edict()\n",
    "cfg.num_point = 1024\n",
    "cfg.num_class = num_class\n",
    "cfg.input_dim = 22 # with normals\n",
    "cfg.model = edict()\n",
    "cfg.model.nblocks = 4\n",
    "cfg.model.nneighbor = 16\n",
    "cfg.model.transformer_dim = 512\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = PointTransformerSeg(cfg).cuda()\n",
    "checkpoint = torch.load(model_path)\n",
    "state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09ff5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_shuffle_region(arr):\n",
    "    region = arr[250:300]\n",
    "    np.random.shuffle(region)\n",
    "    arr[250:300] = region\n",
    "    return arr\n",
    "\n",
    "item_index = 1500\n",
    "item = TEST_DATASET[item_index]\n",
    "points, pred, label = infer(model,item)\n",
    "\n",
    "coordinates = np.asarray(points[0][:,:3].cpu())\n",
    "pred = pred[0]\n",
    "#pred = random_shuffle_region(pred)\n",
    "label = label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34a0a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(coordinates, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d5448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "point_transformers",
   "language": "python",
   "name": "point_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
